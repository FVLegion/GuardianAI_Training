# Guardian AI GitHub Actions Setup

This guide helps you set up and run the Guardian AI training pipeline using GitHub Actions with a self-hosted runner.

## ğŸš€ Quick Start

### 1. Prerequisites
- Self-hosted GitHub Actions runner with:
  - Linux OS
  - Python 3.11
  - GPU support (optional, will fallback to CPU)
  - Labels: `[self-hosted, Linux, X64, guardian, gpu]`

### 2. Configure GitHub Secrets
Go to your repository â†’ Settings â†’ Secrets and variables â†’ Actions

Add these secrets:
- `CLEARML_API_ACCESS_KEY`: Your ClearML access key
- `CLEARML_API_SECRET_KEY`: Your ClearML secret key
- `CLEARML_API_HOST`: Your ClearML server URL (e.g., `https://app.clear.ml`)

### 3. Upload Dataset (Optional)
If you have a real dataset:
```bash
python upload_dataset_simple.py
```

If you don't have a dataset, the pipeline will automatically create mock data for testing.

### 4. Trigger Pipeline
Push to the `main` branch or manually trigger the workflow.

## ğŸ“ File Structure

```
your-repo/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ guardian-pipeline-aws.yml    # GitHub Actions workflow
â”œâ”€â”€ Guardian_pipeline_github.py      # Main pipeline script
â”œâ”€â”€ upload_dataset_simple.py         # Dataset upload utility
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ TROUBLESHOOTING.md               # Troubleshooting guide
â””â”€â”€ README_GITHUB_ACTIONS.md        # This file
```

## ğŸ”§ Pipeline Features

### Robust Dataset Handling
- **Primary**: Downloads dataset from ClearML
- **Fallback**: Creates mock dataset if ClearML fails
- **Validation**: Automatically fixes common dataset structure issues

### Lightweight Training
- Optimized for GitHub Actions (reduced epochs, batch size)
- GPU support with CPU fallback
- Comprehensive logging and monitoring

### Error Recovery
- Graceful handling of missing datasets
- Automatic mock data generation
- Detailed error reporting

## ğŸ“Š Expected Output

### Successful Run
```
ğŸ” Checking ClearML configuration...
âœ… ClearML connection successful
âœ… Dataset downloaded successfully
âœ… Found 9 keypoints files in expected structure
âœ… Training completed. Task ID: xxx, Model ID: xxx
ğŸ‰ Guardian AI GitHub Pipeline Completed!
```

### Fallback Mode (Also Valid)
```
ğŸ” Checking ClearML configuration...
âš ï¸  ClearML connection failed
âœ… Mock dataset created successfully for testing purposes
âœ… Training completed. Task ID: xxx, Model ID: xxx
ğŸ‰ Guardian AI GitHub Pipeline Completed!
```

## ğŸ› ï¸ Customization

### Modify Training Parameters
Edit `Guardian_pipeline_github.py`:
```python
train_bilstm_github(
    dataset_path=dataset_path,
    input_size=input_size,
    num_classes=num_classes,
    epochs=20,        # Increase for longer training
    hidden_size=256,  # Increase for larger model
    batch_size=32     # Increase if you have more memory
)
```

### Change Runner Requirements
Edit `.github/workflows/guardian-pipeline-aws.yml`:
```yaml
runs-on: [self-hosted, Linux, X64, your-custom-labels]
```

### Add More Actions
The workflow can be extended with additional steps:
```yaml
- name: Deploy Model
  run: |
    python deploy_model.py
    
- name: Run Tests
  run: |
    python -m pytest tests/
```

## ğŸ› Troubleshooting

### Common Issues

1. **"Dataset setup failed"**
   - Check ClearML credentials in GitHub Secrets
   - Run `python upload_dataset_simple.py` to create a test dataset

2. **Runner not picking up jobs**
   - Verify runner labels match workflow requirements
   - Check runner status in GitHub repository settings

3. **Memory issues**
   - Reduce `batch_size` in the training parameters
   - Ensure runner has sufficient RAM

4. **GPU not detected**
   - Pipeline will automatically fallback to CPU
   - Check CUDA installation on runner

### Debug Mode
For detailed debugging, check the GitHub Actions logs for:
- ClearML configuration status
- Dataset download progress
- Training metrics and progress

## ğŸ“ˆ Monitoring

### ClearML Dashboard
If ClearML is configured, you can monitor:
- Training progress and metrics
- Model artifacts and versions
- Experiment comparisons

### GitHub Actions
Monitor pipeline execution:
- Build status and logs
- Execution time and resource usage
- Success/failure notifications

## ğŸ”„ Continuous Integration

The pipeline runs automatically on:
- Push to `main` branch
- Manual workflow dispatch

You can modify the trigger in `.github/workflows/guardian-pipeline-aws.yml`:
```yaml
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * 0'  # Weekly on Sunday at 2 AM
```

## ğŸ“š Additional Resources

- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Detailed troubleshooting guide
- [ClearML Documentation](https://clear.ml/docs) - ClearML setup and usage
- [GitHub Actions Documentation](https://docs.github.com/en/actions) - GitHub Actions reference

## ğŸ†˜ Getting Help

If you encounter issues:

1. Check [TROUBLESHOOTING.md](TROUBLESHOOTING.md) for common solutions
2. Review GitHub Actions logs for error details
3. Test ClearML connection manually on your runner
4. Try the mock dataset approach for initial testing

The pipeline is designed to be robust and will work even without ClearML configured! 