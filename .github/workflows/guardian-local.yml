name: Run Guardian AI Pipeline Locally (Disabled - Self-hosted runner required)

# Disabled: This workflow requires a self-hosted runner with local dataset access
# Use guardian-local-trigger.yml instead for the new local GPU execution system
# on:
#   push:
#     branches: [main]
#   pull_request:
#     branches: [main]
#   workflow_dispatch:  # Allow manual triggering

# Uncomment the 'on' section above if you have a self-hosted GitHub Actions runner
on:
  workflow_dispatch:  # Manual triggering only

jobs:
  run_guardian_local:
    runs-on: self-hosted  # Use self-hosted runner with local dataset access
    timeout-minutes: 240  # 4 hours timeout for training

    env:
      CLEARML_API_ACCESS_KEY: ${{ secrets.CLEARML_API_ACCESS_KEY }}
      CLEARML_API_SECRET_KEY: ${{ secrets.CLEARML_API_SECRET_KEY }}
      CLEARML_API_HOST: ${{ secrets.CLEARML_API_HOST }}

    steps:
      - name: âš ï¸ Self-hosted Runner Notice
        run: |
          echo "âš ï¸  WARNING: This workflow requires a self-hosted GitHub Actions runner"
          echo "ðŸ  Use the new local GPU execution system instead:"
          echo "   1. Run: start_local_listener.bat (Windows) or python local_pipeline_listener.py"
          echo "   2. Trigger via: guardian-local-trigger.yml workflow"
          echo "   3. See: LOCAL_EXECUTION_GUIDE.md for setup instructions"
          echo ""
          echo "ðŸ”§ To use this workflow:"
          echo "   1. Set up a self-hosted GitHub Actions runner"
          echo "   2. Ensure local dataset is available at data/Guardian_Dataset"
          echo "   3. Uncomment the 'on' triggers in this workflow"

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify Local Dataset
        run: |
          echo "ðŸ” Checking for local dataset..."
          if [ -d "data/Guardian_Dataset" ]; then
            echo "âœ… Local dataset found"
            echo "ðŸ“Š Dataset contents:"
            find data/Guardian_Dataset -name "*_keypoints.json" | wc -l | xargs echo "Total keypoint files:"
            for action in "Falling" "No Action" "Waving"; do
              if [ -d "data/Guardian_Dataset/$action" ]; then
                count=$(find "data/Guardian_Dataset/$action" -name "*_keypoints.json" | wc -l)
                echo "  - $action: $count files"
              else
                echo "  - $action: âŒ Directory not found"
              fi
            done
          else
            echo "âŒ Local dataset not found at data/Guardian_Dataset"
            echo "Please ensure the dataset is available on the self-hosted runner"
            exit 1
          fi

      - name: Debug ClearML Environment
        run: |
          echo "ðŸ” Checking ClearML configuration..."
          echo "CLEARML_API_HOST=$CLEARML_API_HOST"
          if [ -z "$CLEARML_API_HOST" ]; then 
            echo "âŒ CLEARML_API_HOST is empty!"
            exit 1
          fi
          if [ -z "$CLEARML_API_ACCESS_KEY" ]; then 
            echo "âŒ CLEARML_API_ACCESS_KEY is empty!"
            exit 1
          fi
          echo "âœ… ClearML environment variables are set"
          
          # Test ClearML connection
          python -c "
          from clearml import Task
          print('âœ… ClearML import successful')
          try:
              from clearml.backend_api.session.client import APIClient
              client = APIClient()
              print('âœ… ClearML API connection successful')
          except Exception as e:
              print(f'âŒ ClearML connection failed: {e}')
              exit(1)
          "

      - name: Run Guardian Pipeline Locally
        run: |
          echo "ðŸš€ Starting Guardian AI Training Pipeline (Local Mode)..."
          python Guardian_pipeline.py

      - name: Upload Training Artifacts
        if: always()  # Upload even if pipeline fails
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts-local-${{ github.run_id }}
          path: |
            training_metrics.png
            *.pth
            *.png
            evaluation_outputs/
          retention-days: 30

      - name: Pipeline Summary
        if: always()
        run: |
          echo "## ðŸŽ¯ Guardian AI Pipeline Summary (Local)" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner**: Self-hosted (Local Dataset)" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.head_ref || github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Training Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "training_metrics.png" ]; then
            echo "âœ… Training metrics generated" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Training metrics not found" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”— Links" >> $GITHUB_STEP_SUMMARY
          echo "- [ClearML Dashboard](https://app.clear.ml/)" >> $GITHUB_STEP_SUMMARY
          echo "- [Training Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY 