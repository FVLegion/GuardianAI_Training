name: Guardian AI Pipeline (Fixed)

on:
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      dataset_source:
        description: 'Dataset source'
        required: true
        default: 'github_release'
        type: choice
        options:
        - github_release
        - clearml

jobs:
  run_guardian_pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 180

    env:
      CLEARML_API_ACCESS_KEY: ${{ secrets.CLEARML_API_ACCESS_KEY }}
      CLEARML_API_SECRET_KEY: ${{ secrets.CLEARML_API_SECRET_KEY }}
      CLEARML_API_HOST: ${{ secrets.CLEARML_API_HOST }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download Dataset from GitHub Release
        if: ${{ github.event.inputs.dataset_source == 'github_release' || github.event.inputs.dataset_source == '' }}
        run: |
          echo "ðŸ“¦ Downloading dataset from GitHub release..."
          
          # Download the latest release asset
          REPO="${{ github.repository }}"
          ASSET_NAME="guardian_dataset.zip"
          
          # Get the latest release
          RELEASE_URL="https://api.github.com/repos/$REPO/releases/latest"
          echo "ðŸ” Checking latest release: $RELEASE_URL"
          
          # Download the dataset zip
          wget -O guardian_dataset.zip "https://github.com/$REPO/releases/latest/download/$ASSET_NAME" || {
            echo "âŒ Failed to download from release. Trying alternative..."
            # Fallback: create minimal test dataset
            mkdir -p data/Guardian_Dataset/{Falling,No\ Action,Waving}
            echo "âš ï¸  Using minimal test dataset"
          }
          
          # Extract if downloaded successfully
          if [ -f "guardian_dataset.zip" ]; then
            echo "ðŸ“‚ Extracting dataset..."
            unzip -q guardian_dataset.zip
            ls -la data/Guardian_Dataset/
            echo "âœ… Dataset extracted successfully"
          fi

      - name: Download Dataset from ClearML
        if: ${{ github.event.inputs.dataset_source == 'clearml' }}
        run: |
          echo "ðŸ§ª Testing ClearML dataset access..."
          python test_clearml_dataset.py || {
            echo "âŒ ClearML dataset access failed"
            echo "Creating minimal test dataset..."
            mkdir -p data/Guardian_Dataset/{Falling,No\ Action,Waving}
          }

      - name: Verify Dataset Structure
        run: |
          echo "ðŸ” Verifying dataset structure..."
          if [ -d "data/Guardian_Dataset" ]; then
            echo "âœ… Dataset directory exists"
            ls -la data/Guardian_Dataset/
            
            for action in "Falling" "No Action" "Waving"; do
              if [ -d "data/Guardian_Dataset/$action" ]; then
                count=$(find "data/Guardian_Dataset/$action" -name "*.json" | wc -l)
                echo "  $action: $count JSON files"
              else
                echo "  âŒ Missing: $action"
              fi
            done
          else
            echo "âŒ Dataset directory not found"
            exit 1
          fi

      - name: Run Guardian Pipeline
        run: |
          echo "ðŸš€ Starting Guardian AI Training Pipeline..."
          # Modify the pipeline to use local data path
          export DATASET_PATH="data/Guardian_Dataset"
          python Guardian_pipeline.py

      - name: Upload Training Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts-${{ github.run_number }}
          path: |
            training_metrics.png
            *.pth
            *.png
            evaluation_outputs/
          retention-days: 30

      - name: Pipeline Summary
        if: always()
        run: |
          echo "## ðŸŽ¯ Guardian AI Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Dataset Source**: ${{ github.event.inputs.dataset_source || 'github_release' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.head_ref || github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "training_metrics.png" ]; then
            echo "âœ… Training completed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Training failed or incomplete" >> $GITHUB_STEP_SUMMARY 