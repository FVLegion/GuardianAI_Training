name: Run GuardianAi pipeline on self-hosted aws runner

on:
  push:
    branches:
      - main

jobs:
  run-pipeline:
    runs-on: [self-hosted, Linux, X64, guardian, gpu]   # must match the labels you set
    timeout-minutes: 500 # 8.33 hours
    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgl1-mesa-glx
          sudo apt-get install -y libglib2.0-0

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Setup dataset symlink
        run: |
          echo "üîó Setting up dataset symlink for self-hosted runner..."
          
          # Check if absolute dataset path exists
          if [ -d "/home/sagemaker-user/data/Guardian_Dataset" ]; then
            echo "‚úÖ Found dataset at absolute path: /home/sagemaker-user/data/Guardian_Dataset"
            
            # Create data directory in workspace
            mkdir -p data
            
            # Create symlink if it doesn't exist
            if [ ! -L "data/Guardian_Dataset" ]; then
              ln -s /home/sagemaker-user/data/Guardian_Dataset data/Guardian_Dataset
              echo "‚úÖ Created symlink: data/Guardian_Dataset -> /home/sagemaker-user/data/Guardian_Dataset"
            else
              echo "‚úÖ Symlink already exists"
            fi
            
            # Verify symlink
            ls -la data/
            echo "üìä Dataset structure:"
            ls -la data/Guardian_Dataset/ | head -10
            
          else
            echo "‚ö†Ô∏è  Absolute dataset path not found. Pipeline will create mock data."
          fi

      - name: Verify ClearML Configuration
        env:
          CLEARML_API_ACCESS_KEY: ${{ secrets.CLEARML_API_ACCESS_KEY }}
          CLEARML_API_SECRET_KEY: ${{ secrets.CLEARML_API_SECRET_KEY }}
          CLEARML_API_HOST: ${{ secrets.CLEARML_API_HOST }}
        run: |
          echo "üîç Checking ClearML configuration..."
          echo "CLEARML_API_HOST: ${CLEARML_API_HOST:-'Not Set'}"
          echo "CLEARML_API_ACCESS_KEY: ${CLEARML_API_ACCESS_KEY:+Set}"
          echo "CLEARML_API_SECRET_KEY: ${CLEARML_API_SECRET_KEY:+Set}"
          
          echo "üß™ Testing ClearML connection..."
          python -c "
          try:
              from clearml import Task
              print('‚úÖ ClearML import successful')
              task = Task.init(project_name='test', task_name='connection_test', auto_connect_frameworks=False)
              print('‚úÖ ClearML connection successful')
              task.close()
          except Exception as e:
              print(f'‚ùå ClearML connection failed: {e}')
              print('This may be expected if credentials are not configured')
          "

      - name: Run ClearML pipeline
        env:
          CLEARML_API_ACCESS_KEY: ${{ secrets.CLEARML_API_ACCESS_KEY }}
          CLEARML_API_SECRET_KEY: ${{ secrets.CLEARML_API_SECRET_KEY }}
          CLEARML_API_HOST: ${{ secrets.CLEARML_API_HOST }}
        run: |
          python Guardian_pipeline_github.py

  deploy-model:
    runs-on: [self-hosted, Linux, X64, guardian, gpu]
    needs: run-pipeline
    if: success()
    timeout-minutes: 30
    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install clearml

      - name: Check deployment status
        env:
          CLEARML_API_ACCESS_KEY: ${{ secrets.CLEARML_API_ACCESS_KEY }}
          CLEARML_API_SECRET_KEY: ${{ secrets.CLEARML_API_SECRET_KEY }}
          CLEARML_API_HOST: ${{ secrets.CLEARML_API_HOST }}
        run: |
          echo "üöÄ Checking model deployment status..."
          
          python -c "
          from clearml import Model
          import sys
          
          try:
              print('üîç Searching for deployed models...')
              
              # Check for deployed models directly
              models = Model.query_models(
                  project_name='Guardian_Training',
                  tags=['deployed', 'production', 'github-actions'],
                  only_published=True,
                  max_results=1,
                  order_by=['-created']
              )
              
              if not models:
                  print('‚ùå No deployed models found with deployment tags')
                  
                  # Try to find any recent models
                  print('üîç Searching for any recent models...')
                  recent_models = Model.query_models(
                      project_name='Guardian_Training',
                      model_name='BiLSTM_ActionRecognition',
                      max_results=3,
                      order_by=['-created']
                  )
                  
                  if recent_models:
                      print(f'üìã Found {len(recent_models)} recent models:')
                      for i, m in enumerate(recent_models):
                          print(f'   {i+1}. Model ID: {m.id}')
                          print(f'      Created: {m.created}')
                          print(f'      Published: {m.published}')
                          print(f'      Tags: {m.tags}')
                  else:
                      print('‚ùå No models found at all')
                  
                  sys.exit(1)
              
              model = models[0]
              print(f'‚úÖ Found deployed model!')
              print(f'üè∑Ô∏è  Model ID: {model.id}')
              print(f'üìÖ Created: {model.created}')
              print(f'üè∑Ô∏è  Tags: {model.tags}')
              
              # Get model metadata for accuracy
              try:
                  design = model.get_model_design()
                  if design and 'test_accuracy' in design:
                      accuracy = design['test_accuracy']
                      print(f'üìä Test Accuracy: {accuracy:.2f}%')
                  else:
                      print('üìä Test Accuracy: Not available in model metadata')
              except Exception as e:
                  print(f'‚ö†Ô∏è  Could not get model design: {e}')
                  
          except Exception as e:
              print(f'‚ùå Error checking deployment: {e}')
              import traceback
              traceback.print_exc()
              sys.exit(1)
          "

      - name: Notify deployment success
        if: success()
        run: |
          echo "üéâ Guardian AI Pipeline completed successfully!"
          echo "‚úÖ Model training, optimization, evaluation, and deployment finished"
          echo "üìà Check ClearML dashboard for detailed results and metrics" 
          